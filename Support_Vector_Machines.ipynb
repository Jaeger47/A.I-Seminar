{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Support_Vector_Machines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaeger47/A.I-Seminar/blob/main/Support_Vector_Machines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VGMKDn3MiSO"
      },
      "source": [
        "## Download the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2NvZ29q7QSv"
      },
      "source": [
        "In this notebook the Pima Indians dataset and Boston house dataset will be used to demonstrate the Support Vector Machine algorithm.\n",
        " \n",
        "Before proceeding to the next sections,  upload the `pima-indians-diabetes.data.csv` and `housing.csv` by running the code below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqS5rXcI_ryk"
      },
      "source": [
        "### Option 1: Upload the data from your Local File System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imcOeUz6_41Z"
      },
      "source": [
        "# Uploading the data from Local File System\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwGtsH9L-3NU"
      },
      "source": [
        "### Option 2: Mount your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FZ73dT2HpLg"
      },
      "source": [
        "# Mount your google drive and copy the authentication key to allow access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Locate the file in your Google Drive directory\n",
        "%cd drive/My\\ Drive/Colab\\ Notebooks/ML\\ training  \n",
        "\n",
        "# Uncomment this if you want to list files in the directory to check if the file is there\n",
        "# %ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4M0oxHJIHzV"
      },
      "source": [
        "# Support Vector Machine as a Classification Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Rlh8VJ2YQWo"
      },
      "source": [
        "## Iris Dataset example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY5CNCgmTPmx"
      },
      "source": [
        "# SVM classification using Iris Dataset\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, datasets\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Select first 2 features / variables\n",
        "X = iris.data[:, :2] \n",
        "y = iris.target\n",
        "feature_names = iris.feature_names[:2]\n",
        "classes = iris.target_names\n",
        "print(f\"Features: {feature_names}\")\n",
        "print(f\"Classes: {classes}\")\n",
        "\n",
        "def make_meshgrid(x, y, h=.02):\n",
        "    x_min, x_max = x.min() - 1, x.max() + 1\n",
        "    y_min, y_max = y.min() - 1, y.max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    return xx, yy\n",
        "\n",
        "def plot_contours(ax, clf, xx, yy, **params):\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    out = ax.contourf(xx, yy, Z, **params)\n",
        "    return out\n",
        "\n",
        "# The classification SVC model\n",
        "model = SVC(kernel=\"linear\")\n",
        "clf = model.fit(X, y)\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "print(f\"Support vectors: \\n{clf.support_vectors_[:4,:]}\") # get support vectors\n",
        "print(f\"Support vectors indices: \\n{clf.support_}\") # get indices of support vectors\n",
        "print(f\"No. of support vectors: \\n{clf.n_support_}\") # get number of support vectors for each class\n",
        "\n",
        "# Title for the plots\n",
        "title = ('Decision surface of linear SVC ')\n",
        "\n",
        "# Set-up grid for plotting.\n",
        "X0, X1 = X[:, 0], X[:, 1]       #X0 - sepal length, X1 - sepal width\n",
        "xx, yy = make_meshgrid(X0, X1)\n",
        "plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
        "ax.set_ylabel(\"{}\".format(feature_names[0]))\n",
        "ax.set_xlabel(\"{}\".format(feature_names[1]))\n",
        "ax.set_xticks(())\n",
        "ax.set_yticks(())\n",
        "ax.set_title(title)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts1AYguWYcEM"
      },
      "source": [
        "## Pima Indians example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF9fCaq4G4P5"
      },
      "source": [
        "# SVM Classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Load the dataset\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, header=0, names=names)\n",
        "array = dataframe.values\n",
        "print(dataframe.head())\n",
        "\n",
        "# Assign the feature columns to X\n",
        "# This is the data we fit to our model\n",
        "X = array[:,0:8]\n",
        "\n",
        "# Assign the ground truth or 'class' column to Y\n",
        "# This is our target variable that our model will try to predict\n",
        "Y = array[:,8]\n",
        "\n",
        "# Split the dataset into 10 folds \n",
        "kfold = KFold(n_splits=10, random_state=None)\n",
        "\n",
        "# Fit data on SVC\n",
        "model = SVC()\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print((\"Accuracy: %f\") % results.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3klCmwrIvSq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXqL-bPVIjGp"
      },
      "source": [
        "# Support Vector Machine as a Regression Algorithm\n",
        "\n",
        "Support Vector Machines (SVM) were developed for binary classification. The technique has been extended for the prediction of real-valued problems called Support Vector Regression (SVR). Like the classification example, SVR is built upon the LIBSVM library. You can create an SVM model for regression using the SVR class.\n",
        "\n",
        "More info on SVR [here](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_dJ-xE4I0Mh",
        "outputId": "baf8cb89-866f-42b6-e28c-6bf7ac478586",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Uploading the data from Local File System\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1d6575eb-a7d2-4d08-8311-6790dfe25d6b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1d6575eb-a7d2-4d08-8311-6790dfe25d6b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Energy_efficiency_DataSet.csv to Energy_efficiency_DataSet.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C0vsUg7IvMH",
        "outputId": "6f489baa-bd65-4b16-aac4-1551c474e737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# SVM Regression\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVR\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "filename = 'Energy_efficiency_DataSet.csv'\n",
        "names = ['RC', 'SA', 'WA', 'RA', 'OH', 'O', 'GA', 'GAD', 'HL', 'CL']\n",
        "#dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
        "dataframe = read_csv('Energy_efficiency_DataSet.csv', names=names, comment='#')\n",
        "array = dataframe.values\n",
        "print(dataframe.head())\n",
        "\n",
        "# Assign the feature columns to X\n",
        "# This is the data we fit to our model\n",
        "X = array[:,0:-2]\n",
        "\n",
        "# Assign the ground truth or 'class' column to Y\n",
        "# This is our target variable that our model will try to predict\n",
        "Y1 = array[:,-2]\n",
        "Y2 = array[:,-1]\n",
        "\n",
        "# Split the dataset into 10 folds \n",
        "num_folds = 10\n",
        "kfold = KFold(n_splits=10, random_state=None)\n",
        "\n",
        "# Fit on SVR and calculate MSE\n",
        "model1 = SVR()\n",
        "model2 = SVR()\n",
        "\n",
        "scoring = 'neg_mean_squared_error'\n",
        "results1 = cross_val_score(model1, X, Y1, cv=kfold, scoring=scoring)\n",
        "results2 = cross_val_score(model2, X, Y2, cv=kfold, scoring=scoring)\n",
        "print(results1.mean())\n",
        "print(results2.mean())\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     RC     SA     WA      RA   OH  O   GA  GAD     HL     CL\n",
            "0  0.98  514.5  294.0  110.25  7.0  2  0.0    0  15.55  21.33\n",
            "1  0.98  514.5  294.0  110.25  7.0  3  0.0    0  15.55  21.33\n",
            "2  0.98  514.5  294.0  110.25  7.0  4  0.0    0  15.55  21.33\n",
            "3  0.98  514.5  294.0  110.25  7.0  5  0.0    0  15.55  21.33\n",
            "4  0.90  563.5  318.5  122.50  7.0  2  0.0    0  20.84  28.28\n",
            "-30.426694806412865\n",
            "-25.915327114477158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09x3Ia8SNUBz",
        "outputId": "05ee57c5-b1ad-4098-8cda-46fb3ce9ba3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(Y1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[15.55 15.55 15.55 15.55 20.84 21.46 20.71 19.68 19.5  19.95 19.34 18.31\n",
            " 17.05 17.41 16.95 15.98 28.52 29.9  29.63 28.75 24.77 23.93 24.77 23.93\n",
            "  6.07  6.05  6.01  6.04  6.37  6.4   6.37  6.4   6.85  6.79  6.77  6.81\n",
            "  7.18  7.1   7.1   7.1  10.85 10.54 10.77 10.56  8.6   8.49  8.45  8.5\n",
            " 24.58 24.63 24.63 24.59 29.03 29.87 29.14 28.09 26.28 26.91 26.37 25.27\n",
            " 23.53 24.03 23.54 22.58 35.56 37.12 36.9  35.94 32.96 32.12 32.94 32.21\n",
            " 10.36 10.43 10.36 10.39 10.71 10.8  10.7  10.75 11.11 11.13 11.09 11.16\n",
            " 11.68 11.69 11.7  11.69 15.41 15.2  15.42 15.21 12.96 12.97 12.93 13.02\n",
            " 24.29 24.31 24.13 24.25 28.88 29.68 28.83 27.9  26.48 27.02 26.33 25.36\n",
            " 23.75 24.23 23.67 22.79 35.65 37.26 36.97 36.03 33.16 32.4  33.12 32.41\n",
            " 10.42 10.46 10.32 10.45 10.64 10.72 10.55 10.68 11.45 11.46 11.32 11.49\n",
            " 11.45 11.42 11.33 11.43 15.41 15.18 15.34 15.19 12.88 13.   12.97 13.04\n",
            " 24.28 24.4  24.11 24.35 28.07 29.01 29.62 29.05 25.41 26.47 26.89 26.46\n",
            " 22.93 23.84 24.17 23.87 35.78 35.48 36.97 36.7  32.52 33.28 32.33 33.24\n",
            " 10.39 10.34 10.35 10.38 10.77 10.68 10.68 10.7  11.22 11.16 11.1  11.14\n",
            " 11.59 11.6  11.53 11.61 15.16 15.36 15.12 15.36 12.68 12.63 12.71 12.73\n",
            " 24.38 24.23 24.04 24.32 29.06 28.05 28.86 29.79 26.44 25.37 26.33 27.03\n",
            " 23.8  22.8  23.59 24.24 36.86 35.89 35.45 37.1  33.08 32.38 33.09 32.31\n",
            " 10.08 10.15 10.07 10.14 10.66 10.68 10.53 10.72 11.18 11.22 11.07 11.2\n",
            " 11.44 11.42 11.33 11.43 15.4  15.19 15.32 15.16 12.85 13.04 13.   13.\n",
            " 24.35 24.33 24.03 24.26 29.83 29.08 28.03 29.02 27.03 26.45 25.36 26.45\n",
            " 24.37 23.89 22.89 23.86 37.03 36.71 36.77 35.48 32.31 33.21 32.46 33.27\n",
            " 10.47 10.37 10.34 10.39 10.78 10.7  10.67 13.69 11.21 11.14 11.11 11.16\n",
            " 11.38 11.34 11.22 11.34 15.16 15.37 15.12 15.36 12.59 12.74 12.8  12.62\n",
            " 28.15 28.15 28.37 28.41 32.68 33.48 32.84 32.   29.54 30.05 29.6  28.66\n",
            " 26.84 27.27 26.97 26.19 38.67 40.03 39.86 39.04 36.96 36.13 36.91 36.43\n",
            " 12.43 12.5  12.41 12.45 12.57 12.65 12.57 12.63 12.78 12.93 12.73 12.72\n",
            " 13.17 13.18 13.17 13.18 17.5  17.35 17.52 17.37 15.09 15.12 15.08 15.16\n",
            " 28.67 28.57 28.18 28.6  32.46 33.27 32.33 31.66 29.34 29.87 29.27 28.4\n",
            " 25.74 25.98 25.38 24.94 38.57 40.19 39.97 38.98 36.95 36.28 36.86 36.45\n",
            " 12.35 12.45 12.16 12.3  12.33 12.29 12.2  12.49 12.85 12.87 12.73 12.95\n",
            " 13.05 12.93 12.77 13.   17.14 16.84 17.02 17.11 14.34 14.66 14.6  14.6\n",
            " 28.67 28.56 28.17 28.63 31.63 32.4  32.68 32.29 28.4  29.4  29.43 29.07\n",
            " 24.7  25.48 25.37 25.17 39.04 38.35 39.81 39.83 35.99 36.59 35.64 36.52\n",
            " 11.8  12.03 11.98 11.69 12.41 12.28 12.1  12.19 12.34 12.46 12.31 12.12\n",
            " 12.97 13.01 12.74 12.84 16.83 16.93 16.66 16.86 13.91 14.34 13.95 13.99\n",
            " 28.7  28.55 28.15 28.62 32.67 31.69 32.07 33.28 29.47 28.42 29.08 29.88\n",
            " 25.66 24.96 25.43 26.   40.   38.84 38.33 40.12 36.95 36.45 36.81 36.26\n",
            " 12.32 12.3  12.18 12.43 12.36 12.49 12.17 12.28 12.91 12.95 12.67 12.86\n",
            " 12.95 13.   12.86 12.92 16.99 16.69 16.56 16.62 14.33 14.61 14.61 14.65\n",
            " 28.69 28.58 28.15 28.61 33.13 32.31 31.53 32.46 29.71 29.09 28.31 29.39\n",
            " 25.7  25.17 24.6  25.49 39.89 39.83 39.01 38.65 35.69 36.64 36.06 36.7\n",
            " 12.12 11.67 11.64 12.02 12.27 12.19 12.25 12.27 12.47 12.12 12.18 12.47\n",
            " 12.93 12.82 12.78 13.02 16.73 16.86 16.76 16.92 13.68 13.99 14.16 13.86\n",
            " 32.26 32.26 32.49 32.53 36.47 37.24 36.66 35.96 31.89 32.39 32.09 31.29\n",
            " 29.22 29.91 29.53 28.65 41.4  42.62 42.5  41.67 40.78 39.97 40.71 40.43\n",
            " 14.52 14.61 14.5  14.55 14.51 14.6  14.5  14.58 14.51 14.7  14.42 14.42\n",
            " 15.23 15.23 15.23 15.23 19.52 19.36 19.48 19.42 15.09 17.17 17.14 17.14\n",
            " 32.82 32.71 32.24 32.72 35.84 36.57 36.06 35.69 32.48 32.74 32.13 31.64\n",
            " 28.95 29.49 28.64 28.01 41.64 43.1  42.74 41.92 40.78 40.15 40.57 40.42\n",
            " 14.54 14.45 14.18 14.5  14.7  14.66 14.4  14.71 14.75 14.71 14.33 14.62\n",
            " 15.34 15.29 15.09 15.3  19.2  18.88 18.9  19.12 16.76 17.23 17.26 17.15\n",
            " 32.82 32.69 32.23 32.75 34.24 34.95 35.05 34.29 31.28 32.12 32.05 31.84\n",
            " 28.67 29.67 29.47 28.91 41.26 41.3  42.49 42.08 39.32 39.84 38.89 39.68\n",
            " 13.97 14.22 14.1  13.78 14.07 14.03 13.94 13.86 14.32 14.56 14.33 14.08\n",
            " 15.16 15.18 14.72 14.9  18.48 18.71 18.48 18.46 16.47 16.35 16.55 16.74\n",
            " 32.85 32.67 32.21 32.74 36.45 35.73 35.4  36.57 32.38 31.66 32.15 32.75\n",
            " 28.93 28.05 28.64 29.52 42.77 41.73 41.32 42.96 40.68 40.4  40.6  40.11\n",
            " 14.37 14.48 14.32 14.44 14.6  14.7  14.47 14.66 14.54 14.62 14.53 14.71\n",
            " 15.34 15.29 15.09 15.3  19.06 19.13 19.   18.84 16.44 16.9  16.94 16.77\n",
            " 32.84 32.72 32.21 32.73 35.67 35.01 34.72 35.24 32.31 31.81 31.12 32.06\n",
            " 30.   29.5  29.06 29.92 42.11 41.96 41.09 40.79 38.82 39.72 39.31 39.86\n",
            " 14.41 14.19 14.17 14.39 12.43 12.63 12.76 12.42 14.12 14.28 14.37 14.21\n",
            " 14.96 14.92 14.92 15.16 17.69 18.19 18.16 17.88 16.54 16.44 16.48 16.64]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nug53D_6NYbK",
        "outputId": "a4d9d8be-ca30-4beb-a891-83f6e5e166b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(Y2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[21.33 21.33 21.33 21.33 28.28 25.38 25.16 29.6  27.3  21.97 23.49 27.87\n",
            " 23.77 21.46 21.16 24.93 37.73 31.27 30.93 39.44 29.79 29.68 29.79 29.4\n",
            " 10.9  11.19 10.94 11.17 11.27 11.72 11.29 11.67 11.74 12.05 11.73 11.93\n",
            " 12.4  12.23 12.4  12.14 16.78 16.8  16.75 16.67 12.07 12.22 12.08 12.04\n",
            " 26.47 26.37 26.44 26.29 32.92 29.87 29.58 34.33 30.89 25.6  27.03 31.73\n",
            " 27.31 24.91 24.61 28.51 41.68 35.28 34.43 43.33 33.87 34.07 34.14 33.67\n",
            " 13.43 13.71 13.48 13.7  13.8  14.28 13.87 14.27 14.28 14.61 14.3  14.45\n",
            " 13.9  13.72 13.88 13.65 19.37 19.43 19.34 19.32 14.34 14.5  14.33 14.27\n",
            " 25.95 25.63 26.13 25.89 32.54 29.44 29.36 34.2  30.91 25.63 27.36 31.9\n",
            " 27.38 25.02 24.8  28.79 41.07 34.62 33.87 42.86 33.91 34.07 34.17 33.78\n",
            " 13.39 13.72 13.57 13.79 13.67 14.11 13.8  14.21 13.2  13.54 13.32 13.51\n",
            " 14.86 14.75 15.   14.74 19.23 19.34 19.32 19.3  14.37 14.57 14.27 14.24\n",
            " 25.68 26.02 25.84 26.14 34.14 32.85 30.08 29.67 31.73 31.01 25.9  27.4\n",
            " 28.68 27.54 25.35 24.93 43.12 41.22 35.1  34.29 33.85 34.11 34.48 34.5\n",
            " 13.6  13.36 13.65 13.49 14.14 13.77 14.3  13.87 14.44 14.27 14.67 14.4\n",
            " 13.46 13.7  13.59 13.83 19.14 19.18 19.37 19.29 14.09 14.23 14.14 13.89\n",
            " 25.91 25.72 26.18 25.87 29.34 33.91 32.83 29.92 27.17 31.76 31.06 25.81\n",
            " 24.61 28.61 27.57 25.16 34.25 43.3  41.86 35.29 34.11 33.62 33.89 34.05\n",
            " 13.2  13.36 13.21 13.53 13.67 14.12 13.79 14.2  14.29 14.49 14.42 14.73\n",
            " 14.86 14.67 15.   14.83 19.24 19.25 19.42 19.48 14.37 14.34 14.28 14.47\n",
            " 25.64 25.98 25.88 26.18 29.82 29.52 34.45 33.01 25.82 27.33 32.04 31.28\n",
            " 25.11 24.77 28.88 27.69 34.99 34.18 43.14 41.26 34.25 34.35 33.64 33.88\n",
            " 13.65 13.44 13.72 13.5  14.18 13.75 14.26 13.89 14.55 14.28 14.46 14.39\n",
            " 14.54 14.81 14.65 14.87 19.24 19.18 19.26 19.29 14.24 13.97 13.99 14.15\n",
            " 29.79 29.79 29.28 29.49 36.12 33.17 32.71 37.58 33.98 28.61 30.12 34.73\n",
            " 30.17 27.84 27.25 31.39 43.8  37.81 36.85 45.52 36.85 37.58 37.45 36.62\n",
            " 15.19 15.5  15.28 15.5  15.42 15.85 15.44 15.81 15.21 15.63 15.48 15.78\n",
            " 16.39 16.27 16.39 16.19 21.13 21.19 21.09 21.08 15.77 15.95 15.77 15.76\n",
            " 29.62 29.69 30.18 30.02 35.56 32.64 32.77 37.72 33.37 27.89 29.9  34.52\n",
            " 28.27 26.96 26.72 29.88 43.86 37.41 36.77 45.97 36.87 37.35 37.28 36.81\n",
            " 14.73 15.1  15.18 15.44 14.91 15.4  14.94 15.32 15.52 15.85 15.66 15.99\n",
            " 15.89 15.85 16.22 15.87 20.47 20.56 20.48 20.43 15.32 15.64 15.14 15.3\n",
            " 29.43 29.78 30.1  30.19 36.35 35.1  32.83 32.46 33.52 32.93 28.38 29.82\n",
            " 28.77 27.76 26.95 26.41 45.13 43.66 37.76 36.87 36.07 36.44 37.28 37.29\n",
            " 14.49 13.79 14.72 14.76 14.92 14.74 15.57 14.94 14.92 14.38 15.44 15.17\n",
            " 15.53 15.8  16.14 16.26 19.87 20.03 20.46 20.28 14.89 14.96 14.89 14.35\n",
            " 29.61 29.59 30.19 30.12 32.12 37.12 36.16 33.16 29.45 34.19 33.93 28.31\n",
            " 26.3  29.43 28.76 27.34 36.26 45.48 44.16 37.26 37.2  36.76 37.05 37.51\n",
            " 14.92 15.24 15.03 15.35 14.67 15.09 15.2  15.64 15.37 15.73 15.83 16.13\n",
            " 15.95 15.59 16.17 16.14 19.65 19.76 20.37 19.9  15.41 15.56 15.07 15.38\n",
            " 29.53 29.77 30.   30.2  32.25 32.   37.19 35.62 28.02 29.43 34.15 33.47\n",
            " 26.53 26.08 29.31 28.14 37.54 36.66 45.28 43.73 36.93 37.01 35.73 36.15\n",
            " 14.48 14.58 14.81 14.03 15.27 14.71 15.23 14.97 15.14 14.97 15.22 14.6\n",
            " 15.83 16.03 15.8  16.06 20.13 20.01 20.19 20.29 15.19 14.61 14.61 14.75\n",
            " 33.37 33.34 32.83 33.04 39.28 36.38 35.92 40.99 35.99 30.66 31.7  36.73\n",
            " 31.71 29.13 28.99 33.54 45.29 39.07 38.35 46.94 39.55 40.85 40.63 39.48\n",
            " 16.94 17.25 17.03 17.25 17.1  17.51 17.12 17.47 16.5  17.   16.87 17.2\n",
            " 18.14 18.03 18.14 17.95 22.72 22.73 22.72 22.53 17.2  17.21 17.15 17.2\n",
            " 32.96 33.13 33.94 33.78 38.35 35.39 34.94 40.66 35.48 30.53 32.28 36.86\n",
            " 30.34 27.93 28.95 32.92 45.59 39.41 38.84 48.03 39.48 40.4  40.47 39.7\n",
            " 16.43 16.93 16.99 17.03 16.77 17.37 17.27 17.51 16.44 17.01 17.23 17.22\n",
            " 17.85 17.89 18.36 18.15 21.72 22.07 22.09 21.93 17.36 17.38 16.86 16.99\n",
            " 32.78 33.24 33.86 34.   37.26 35.04 33.82 33.31 35.22 34.7  30.11 31.6\n",
            " 32.43 30.65 29.77 29.64 46.44 44.18 38.81 38.23 38.17 38.48 39.66 40.1\n",
            " 16.08 15.39 16.57 16.6  16.11 15.47 16.7  16.1  16.35 15.84 16.99 17.02\n",
            " 17.04 17.63 18.1  18.22 20.78 20.72 21.54 21.53 16.9  17.14 16.56 16.\n",
            " 32.95 33.06 33.95 33.88 33.98 39.92 39.22 36.1  31.53 36.2  36.21 31.\n",
            " 28.2  32.35 31.14 28.43 38.33 47.59 46.23 39.56 40.36 39.67 39.85 40.77\n",
            " 16.61 16.74 16.9  17.32 16.85 17.2  17.23 17.74 16.81 16.88 16.9  17.39\n",
            " 17.86 17.82 18.36 18.24 21.68 21.54 22.25 22.49 17.1  16.79 16.58 16.79\n",
            " 32.88 33.23 33.76 34.01 33.94 33.14 38.79 37.27 29.69 31.2  36.26 35.71\n",
            " 29.93 29.56 33.84 32.54 38.56 37.7  47.01 44.87 39.37 39.8  37.79 38.18\n",
            " 16.69 16.62 16.94 16.7  15.59 14.58 15.33 15.31 16.63 15.87 16.54 16.74\n",
            " 17.64 17.79 17.55 18.06 20.82 20.21 20.71 21.4  16.88 17.11 16.61 16.03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBiModA6Klkt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}